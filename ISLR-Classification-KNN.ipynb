{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/areum/Documents/ISLR/Smarket.csv\", index_col=0, usecols=range(1,10), parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "Year                                                                  \n",
       "2001-01-01  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "2001-01-01  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2001-01-01  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "2001-01-01 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "2001-01-01  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1250 entries, 2001-01-01 to 2005-01-01\n",
      "Data columns (total 8 columns):\n",
      "Lag1         1250 non-null float64\n",
      "Lag2         1250 non-null float64\n",
      "Lag3         1250 non-null float64\n",
      "Lag4         1250 non-null float64\n",
      "Lag5         1250 non-null float64\n",
      "Volume       1250 non-null float64\n",
      "Today        1250 non-null float64\n",
      "Direction    1250 non-null object\n",
      "dtypes: float64(7), object(1)\n",
      "memory usage: 87.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][['Lag1', 'Lag2']]\n",
    "y_train = df[:'2004']['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = df['2005':][['Lag1', 'Lag2']]\n",
    "y_test = df['2005':]['Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.426     0.387     0.406       111\n",
      "         Up      0.550     0.589     0.568       141\n",
      "\n",
      "avg / total      0.495     0.500     0.497       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 58]\n",
      " [68 83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred3 = knn3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.466     0.432     0.449       111\n",
      "         Up      0.577     0.610     0.593       141\n",
      "\n",
      "avg / total      0.528     0.532     0.529       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred3, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 55]\n",
      " [63 86]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred3).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.426     0.387     0.406       111\n",
      "         Up      0.550     0.589     0.568       141\n",
      "\n",
      "avg / total      0.495     0.500     0.497       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.443     0.667     0.532       111\n",
      "         Up      0.565     0.340     0.425       141\n",
      "\n",
      "avg / total      0.511     0.484     0.472       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.466     0.432     0.449       111\n",
      "         Up      0.577     0.610     0.593       141\n",
      "\n",
      "avg / total      0.528     0.532     0.529       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.464     0.640     0.538       111\n",
      "         Up      0.596     0.418     0.492       141\n",
      "\n",
      "avg / total      0.538     0.516     0.512       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.404     0.360     0.381       111\n",
      "         Up      0.536     0.582     0.558       141\n",
      "\n",
      "avg / total      0.478     0.484     0.480       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.444     0.568     0.498       111\n",
      "         Up      0.564     0.440     0.494       141\n",
      "\n",
      "avg / total      0.511     0.496     0.496       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.387     0.369     0.378       111\n",
      "         Up      0.521     0.539     0.530       141\n",
      "\n",
      "avg / total      0.462     0.464     0.463       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.434     0.568     0.492       111\n",
      "         Up      0.551     0.418     0.476       141\n",
      "\n",
      "avg / total      0.500     0.484     0.483       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.425     0.405     0.415       111\n",
      "         Up      0.548     0.567     0.557       141\n",
      "\n",
      "avg / total      0.494     0.496     0.495       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.465     0.604     0.525       111\n",
      "         Up      0.593     0.454     0.514       141\n",
      "\n",
      "avg / total      0.537     0.520     0.519       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 11\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.467     0.450     0.459       111\n",
      "         Up      0.579     0.596     0.587       141\n",
      "\n",
      "avg / total      0.530     0.532     0.531       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 12\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.460     0.577     0.512       111\n",
      "         Up      0.584     0.468     0.520       141\n",
      "\n",
      "avg / total      0.530     0.516     0.516       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 13\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.434     0.414     0.424       111\n",
      "         Up      0.555     0.574     0.564       141\n",
      "\n",
      "avg / total      0.502     0.504     0.503       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.402     0.477     0.436       111\n",
      "         Up      0.517     0.440     0.475       141\n",
      "\n",
      "avg / total      0.466     0.456     0.458       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.408     0.378     0.393       111\n",
      "         Up      0.537     0.567     0.552       141\n",
      "\n",
      "avg / total      0.480     0.484     0.482       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 16\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.389     0.441     0.414       111\n",
      "         Up      0.508     0.454     0.479       141\n",
      "\n",
      "avg / total      0.455     0.448     0.450       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 17\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.419     0.396     0.407       111\n",
      "         Up      0.544     0.567     0.556       141\n",
      "\n",
      "avg / total      0.489     0.492     0.490       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 18\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.403     0.432     0.417       111\n",
      "         Up      0.526     0.496     0.511       141\n",
      "\n",
      "avg / total      0.472     0.468     0.470       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.439     0.387     0.411       111\n",
      "         Up      0.558     0.610     0.583       141\n",
      "\n",
      "avg / total      0.506     0.512     0.507       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.415     0.441     0.428       111\n",
      "         Up      0.537     0.511     0.524       141\n",
      "\n",
      "avg / total      0.484     0.480     0.481       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 21\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.427     0.369     0.396       111\n",
      "         Up      0.551     0.610     0.579       141\n",
      "\n",
      "avg / total      0.497     0.504     0.499       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 22\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.447     0.459     0.453       111\n",
      "         Up      0.565     0.553     0.559       141\n",
      "\n",
      "avg / total      0.513     0.512     0.513       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 23\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.414     0.369     0.390       111\n",
      "         Up      0.542     0.589     0.565       141\n",
      "\n",
      "avg / total      0.486     0.492     0.488       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.432     0.459     0.445       111\n",
      "         Up      0.552     0.525     0.538       141\n",
      "\n",
      "avg / total      0.499     0.496     0.497       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.413     0.387     0.400       111\n",
      "         Up      0.541     0.567     0.554       141\n",
      "\n",
      "avg / total      0.485     0.488     0.486       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.429     0.486     0.456       111\n",
      "         Up      0.548     0.489     0.517       141\n",
      "\n",
      "avg / total      0.495     0.488     0.490       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.421     0.405     0.413       111\n",
      "         Up      0.545     0.560     0.552       141\n",
      "\n",
      "avg / total      0.490     0.492     0.491       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 28\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.414     0.477     0.444       111\n",
      "         Up      0.532     0.468     0.498       141\n",
      "\n",
      "avg / total      0.480     0.472     0.474       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.438     0.441     0.439       111\n",
      "         Up      0.557     0.553     0.555       141\n",
      "\n",
      "avg / total      0.504     0.504     0.504       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.444     0.495     0.468       111\n",
      "         Up      0.562     0.511     0.535       141\n",
      "\n",
      "avg / total      0.510     0.504     0.506       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.415     0.396     0.406       111\n",
      "         Up      0.541     0.560     0.551       141\n",
      "\n",
      "avg / total      0.486     0.488     0.487       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.430     0.468     0.448       111\n",
      "         Up      0.550     0.511     0.529       141\n",
      "\n",
      "avg / total      0.497     0.492     0.494       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.424     0.378     0.400       111\n",
      "         Up      0.549     0.596     0.571       141\n",
      "\n",
      "avg / total      0.494     0.500     0.496       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.429     0.459     0.443       111\n",
      "         Up      0.549     0.518     0.533       141\n",
      "\n",
      "avg / total      0.496     0.492     0.493       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 35\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.430     0.387     0.408       111\n",
      "         Up      0.553     0.596     0.573       141\n",
      "\n",
      "avg / total      0.499     0.504     0.500       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.421     0.459     0.440       111\n",
      "         Up      0.542     0.504     0.522       141\n",
      "\n",
      "avg / total      0.489     0.484     0.486       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 37\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.417     0.387     0.402       111\n",
      "         Up      0.544     0.574     0.559       141\n",
      "\n",
      "avg / total      0.488     0.492     0.490       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 38\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.426     0.468     0.446       111\n",
      "         Up      0.546     0.504     0.524       141\n",
      "\n",
      "avg / total      0.493     0.488     0.490       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 39\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.426     0.387     0.406       111\n",
      "         Up      0.550     0.589     0.568       141\n",
      "\n",
      "avg / total      0.495     0.500     0.497       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.437     0.468     0.452       111\n",
      "         Up      0.556     0.525     0.540       141\n",
      "\n",
      "avg / total      0.504     0.500     0.501       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 41\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.434     0.387     0.410       111\n",
      "         Up      0.556     0.603     0.578       141\n",
      "\n",
      "avg / total      0.502     0.508     0.504       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.440     0.459     0.449       111\n",
      "         Up      0.559     0.539     0.549       141\n",
      "\n",
      "avg / total      0.506     0.504     0.505       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.446     0.405     0.425       111\n",
      "         Up      0.563     0.603     0.582       141\n",
      "\n",
      "avg / total      0.511     0.516     0.513       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 44\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.432     0.459     0.445       111\n",
      "         Up      0.552     0.525     0.538       141\n",
      "\n",
      "avg / total      0.499     0.496     0.497       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.432     0.369     0.398       111\n",
      "         Up      0.554     0.617     0.584       141\n",
      "\n",
      "avg / total      0.500     0.508     0.502       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.438     0.441     0.439       111\n",
      "         Up      0.557     0.553     0.555       141\n",
      "\n",
      "avg / total      0.504     0.504     0.504       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 47\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.418     0.369     0.392       111\n",
      "         Up      0.545     0.596     0.569       141\n",
      "\n",
      "avg / total      0.489     0.496     0.491       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.430     0.441     0.436       111\n",
      "         Up      0.551     0.539     0.545       141\n",
      "\n",
      "avg / total      0.497     0.496     0.497       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.429     0.378     0.402       111\n",
      "         Up      0.552     0.603     0.576       141\n",
      "\n",
      "avg / total      0.498     0.504     0.499       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.423     0.423     0.423       111\n",
      "         Up      0.546     0.546     0.546       141\n",
      "\n",
      "avg / total      0.492     0.492     0.492       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.439     0.387     0.411       111\n",
      "         Up      0.558     0.610     0.583       141\n",
      "\n",
      "avg / total      0.506     0.512     0.507       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.469     0.477     0.473       111\n",
      "         Up      0.583     0.574     0.579       141\n",
      "\n",
      "avg / total      0.533     0.532     0.532       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.402     0.351     0.375       111\n",
      "         Up      0.535     0.589     0.561       141\n",
      "\n",
      "avg / total      0.477     0.484     0.479       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.432     0.432     0.432       111\n",
      "         Up      0.553     0.553     0.553       141\n",
      "\n",
      "avg / total      0.500     0.500     0.500       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.420     0.378     0.398       111\n",
      "         Up      0.546     0.589     0.567       141\n",
      "\n",
      "avg / total      0.491     0.496     0.492       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 56\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.445     0.441     0.443       111\n",
      "         Up      0.563     0.567     0.565       141\n",
      "\n",
      "avg / total      0.511     0.512     0.512       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 57\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.441     0.369     0.402       111\n",
      "         Up      0.560     0.631     0.593       141\n",
      "\n",
      "avg / total      0.507     0.516     0.509       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 58\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.459     0.450     0.455       111\n",
      "         Up      0.573     0.582     0.577       141\n",
      "\n",
      "avg / total      0.523     0.524     0.523       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.453     0.387     0.417       111\n",
      "         Up      0.567     0.631     0.597       141\n",
      "\n",
      "avg / total      0.517     0.524     0.518       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 60\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.459     0.450     0.455       111\n",
      "         Up      0.573     0.582     0.577       141\n",
      "\n",
      "avg / total      0.523     0.524     0.523       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.454     0.396     0.423       111\n",
      "         Up      0.568     0.624     0.595       141\n",
      "\n",
      "avg / total      0.517     0.524     0.519       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 62\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.455     0.450     0.452       111\n",
      "         Up      0.570     0.574     0.572       141\n",
      "\n",
      "avg / total      0.519     0.520     0.520       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.454     0.396     0.423       111\n",
      "         Up      0.568     0.624     0.595       141\n",
      "\n",
      "avg / total      0.517     0.524     0.519       252\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.441     0.441     0.441       111\n",
      "         Up      0.560     0.560     0.560       141\n",
      "\n",
      "avg / total      0.508     0.508     0.508       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.443     0.387     0.413       111\n",
      "         Up      0.561     0.617     0.588       141\n",
      "\n",
      "avg / total      0.509     0.516     0.511       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.467     0.450     0.459       111\n",
      "         Up      0.579     0.596     0.587       141\n",
      "\n",
      "avg / total      0.530     0.532     0.531       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.475     0.423     0.448       111\n",
      "         Up      0.582     0.631     0.605       141\n",
      "\n",
      "avg / total      0.535     0.540     0.536       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 68\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.473     0.477     0.475       111\n",
      "         Up      0.586     0.582     0.584       141\n",
      "\n",
      "avg / total      0.536     0.536     0.536       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.464     0.405     0.433       111\n",
      "         Up      0.574     0.631     0.601       141\n",
      "\n",
      "avg / total      0.526     0.532     0.527       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 70\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.473     0.468     0.471       111\n",
      "         Up      0.585     0.589     0.587       141\n",
      "\n",
      "avg / total      0.535     0.536     0.535       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.469     0.414     0.440       111\n",
      "         Up      0.578     0.631     0.603       141\n",
      "\n",
      "avg / total      0.530     0.536     0.532       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.482     0.495     0.489       111\n",
      "         Up      0.594     0.582     0.588       141\n",
      "\n",
      "avg / total      0.545     0.544     0.544       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.449     0.396     0.421       111\n",
      "         Up      0.565     0.617     0.590       141\n",
      "\n",
      "avg / total      0.514     0.520     0.515       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.486     0.486     0.486       111\n",
      "         Up      0.596     0.596     0.596       141\n",
      "\n",
      "avg / total      0.548     0.548     0.548       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.466     0.432     0.449       111\n",
      "         Up      0.577     0.610     0.593       141\n",
      "\n",
      "avg / total      0.528     0.532     0.529       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.465     0.477     0.471       111\n",
      "         Up      0.580     0.567     0.573       141\n",
      "\n",
      "avg / total      0.529     0.528     0.528       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 77\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.440     0.396     0.417       111\n",
      "         Up      0.559     0.603     0.580       141\n",
      "\n",
      "avg / total      0.507     0.512     0.508       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.446     0.450     0.448       111\n",
      "         Up      0.564     0.560     0.562       141\n",
      "\n",
      "avg / total      0.512     0.512     0.512       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.411     0.351     0.379       111\n",
      "         Up      0.541     0.603     0.570       141\n",
      "\n",
      "avg / total      0.484     0.492     0.486       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 80\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.432     0.432     0.432       111\n",
      "         Up      0.553     0.553     0.553       141\n",
      "\n",
      "avg / total      0.500     0.500     0.500       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.412     0.378     0.394       111\n",
      "         Up      0.540     0.574     0.557       141\n",
      "\n",
      "avg / total      0.484     0.488     0.485       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.455     0.459     0.457       111\n",
      "         Up      0.571     0.567     0.569       141\n",
      "\n",
      "avg / total      0.520     0.520     0.520       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 83\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.430     0.414     0.422       111\n",
      "         Up      0.552     0.567     0.559       141\n",
      "\n",
      "avg / total      0.498     0.500     0.499       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.444     0.468     0.456       111\n",
      "         Up      0.563     0.539     0.551       141\n",
      "\n",
      "avg / total      0.511     0.508     0.509       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.433     0.405     0.419       111\n",
      "         Up      0.554     0.582     0.567       141\n",
      "\n",
      "avg / total      0.501     0.504     0.502       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.431     0.423     0.427       111\n",
      "         Up      0.552     0.560     0.556       141\n",
      "\n",
      "avg / total      0.499     0.500     0.499       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.434     0.387     0.410       111\n",
      "         Up      0.556     0.603     0.578       141\n",
      "\n",
      "avg / total      0.502     0.508     0.504       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 88\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.432     0.432     0.432       111\n",
      "         Up      0.553     0.553     0.553       141\n",
      "\n",
      "avg / total      0.500     0.500     0.500       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.433     0.378     0.404       111\n",
      "         Up      0.555     0.610     0.581       141\n",
      "\n",
      "avg / total      0.501     0.508     0.503       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 90\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.451     0.459     0.455       111\n",
      "         Up      0.568     0.560     0.564       141\n",
      "\n",
      "avg / total      0.517     0.516     0.516       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.444     0.396     0.419       111\n",
      "         Up      0.562     0.610     0.585       141\n",
      "\n",
      "avg / total      0.510     0.516     0.512       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.449     0.477     0.463       111\n",
      "         Up      0.567     0.539     0.553       141\n",
      "\n",
      "avg / total      0.515     0.512     0.513       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.426     0.387     0.406       111\n",
      "         Up      0.550     0.589     0.568       141\n",
      "\n",
      "avg / total      0.495     0.500     0.497       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.458     0.486     0.472       111\n",
      "         Up      0.575     0.546     0.560       141\n",
      "\n",
      "avg / total      0.523     0.520     0.521       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.457     0.432     0.444       111\n",
      "         Up      0.571     0.596     0.583       141\n",
      "\n",
      "avg / total      0.521     0.524     0.522       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.462     0.495     0.478       111\n",
      "         Up      0.579     0.546     0.562       141\n",
      "\n",
      "avg / total      0.528     0.524     0.525       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.470     0.423     0.445       111\n",
      "         Up      0.579     0.624     0.601       141\n",
      "\n",
      "avg / total      0.531     0.536     0.532       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.465     0.477     0.471       111\n",
      "         Up      0.580     0.567     0.573       141\n",
      "\n",
      "avg / total      0.529     0.528     0.528       252\n",
      "\n",
      "\n",
      "\n",
      "n_neighbors: 99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down      0.455     0.414     0.434       111\n",
      "         Up      0.570     0.610     0.589       141\n",
      "\n",
      "avg / total      0.519     0.524     0.521       252\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,100):\n",
    "    knn_k = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_k.fit(X_train, y_train)\n",
    "    pred = knn_k.predict(X_test)\n",
    "    print(\"n_neighbors:\", k)\n",
    "    print(classification_report(y_test, pred, digits=3))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
